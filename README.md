# Human Emotion Recognition using Gaussian Mixture Model (GMM)

## ğŸ“Œ Overview

This project aims to classify human emotionsâ€”**Happy, Sad, Angry, Neutral**â€”from voice recordings using the **Gaussian Mixture Model (GMM)**. The primary application areas include:

- **AI-Powered Virtual Assistants** ğŸ™ï¸
- **Mental Health Monitoring** ğŸ¥
- **Human-Computer Interaction & Voice AI** ğŸ¤–

## ğŸš€ Why Gaussian Mixture Model (GMM)?

**Captures Variability**: Voice signals are continuous and can be effectively modeled as a mixture of Gaussian distributions.
**Handles Multi-Modal Distributions**: Unlike traditional classifiers, GMM can model variations within the same emotion class.
**Personalized AI Assistants**: Helps in building adaptive AI that can understand user emotions in real-time. 
**Healthcare Applications**: Supports mental health tracking by analyzing emotional patterns in speech.

## ğŸ“‚ Dataset: RAVDESS Emotional Speech Audio Dataset

We utilize the **RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)** dataset, which contains **professional-quality emotional speech recordings**. This dataset provides diverse emotions expressed through speech, making it ideal for emotion recognition tasks.

## ğŸ”§ How It Works?

1ï¸âƒ£ **Feature Extraction**: Extract **Mel-Frequency Cepstral Coefficients (MFCCs)** from speech signals. 
2ï¸âƒ£ **Modeling Emotions**: Use **Gaussian Mixture Model (GMM)** to cluster voice patterns into emotion categories. 
3ï¸âƒ£ **Gaussian Components**: Fit Gaussian distributions to capture variations in **tone, pitch, and frequency**. 
4ï¸âƒ£ **Classification**: Predict emotions using **maximum likelihood estimation**.

## ğŸ› ï¸ Tech Stack

- **Python** ğŸ
- **Librosa** (Audio Processing) ğŸµ
- **Scikit-learn** (Machine Learning) ğŸ¤–
- **NumPy & Pandas** (Data Handling) ğŸ“Š
- **Matplotlib & Seaborn** (Data Visualization) ğŸ“ˆ

## ğŸ“Š Expected Output

The model classifies voice recordings into one of the four emotions (**Happy, Sad, Angry, Neutral**) with high accuracy. The final results can be visualized through **confusion matrices and emotion distribution plots**.

## ğŸ”® Future Enhancements

- Expand the model to **more emotions** (Fear, Surprise, Disgust).
- Integrate with **real-time emotion detection systems**.
- Fine-tune using **deep learning techniques (LSTMs, CNNs on spectrograms)**.

## ğŸ“ How to Use

1. Install dependencies:
   ```bash
   pip install numpy pandas librosa scikit-learn matplotlib seaborn
   ```
2. Run the script to extract features and train the GMM model.
3. Use the trained model to classify new voice recordings.

---

ğŸš€ **Contributions & Feedback**: Feel free to contribute and suggest improvements! Let's make AI more emotionally intelligent! ğŸ˜Š

